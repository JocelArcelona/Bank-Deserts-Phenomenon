{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0316e8-fbaf-485f-8a96-e1b94f1bdf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058f0c82-c91a-4f61-a797-e8ed1141bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape fdic api and save it to a csv file \n",
    "def fdic_api(url, params, file_path, data_points: int): \n",
    "    \"\"\"\n",
    "    This function retrieves data from the FDIC API in batches, saving it to a CSV file. \n",
    "    It uses pagination by adjusting the 'offset' and 'limit' query parameters for each batch.\n",
    "\n",
    "    Parameters: \n",
    "    url - base url of the FDIC api\n",
    "    params - query parameters for the API (e.g. fields that needs to be included in the dataset being retrieved, format (csv, txt, json etc)\n",
    "    file_path - file path where retrieved file gets saved \n",
    "    data_points - total number of data points available for retrieval (found in the metadata)\n",
    "    \"\"\"\n",
    "    # define total number of fdic limit per API request\n",
    "    fdic_limit = 10000\n",
    "\n",
    "    # calculate number of batches to retrieve all data\n",
    "    total_data_pts = data_points\n",
    "    num_of_batches = (total_data_pts // fdic_limit) + (1 if total_data_pts % fdic_limit > 0 else 0) # if remainder is greater than 0, add 1 to the num batches, otherwise add 0\n",
    "\n",
    "    with open(file_path, 'w', newline = '', encoding = 'utf-8') as file: \n",
    "        writer = None\n",
    "\n",
    "        # update query parameters for each batch\n",
    "        for batch in range(num_of_batches): \n",
    "            params['offset'] = batch * fdic_limit \n",
    "            params['limit'] = fdic_limit # ensures the api only fetches 10000 data points at a time \n",
    "\n",
    "            # make the api request\n",
    "            response = requests.get(url, params)\n",
    "            if response.status_code == 200: \n",
    "                try: \n",
    "                    response_data = response.text.splitlines()\n",
    "                    reader = csv.reader(response_data) # parse the response data into rows using csv.reader\n",
    "                    # write data to file\n",
    "                    if writer is None: \n",
    "                        writer = csv.writer(file) # writes rows to the file\n",
    "                        writer.writerows(reader)\n",
    "                    else: \n",
    "                        next(reader) # skips header row for all other iterations\n",
    "                        writer.writerows(reader)\n",
    "                except Exception as e:\n",
    "                    print(f'An error occurred while reading batch {batch + 1}: {e}')\n",
    "                    raise\n",
    "            else: \n",
    "                print(f'Error: {response.status_code}')\n",
    "                print(f'{response.text}')\n",
    "                break\n",
    "    print(f'All data retrieved successfully. {total_data_pts} data points saved to {file_path}')\n",
    "                \n",
    "    # above function works if api has a limit (needs pagination), otherwise the function below works: \n",
    "    # response = requests.get(url, params)\n",
    "    # if response.status_code == 200:\n",
    "    #     try: \n",
    "    #         response_data = response.text.splitlines()\n",
    "    #         reader = csv.reader(response_data)\n",
    "    #         with open(file_path, 'w', newline = '', encoding = 'utf-8') as file: \n",
    "    #             writer = csv.writer(file)\n",
    "    #             writer.writerows(reader)\n",
    "    #     except Exception as e:\n",
    "    #         print(f'An error occurred while writing to the file: {e}')\n",
    "    #         raise\n",
    "    # else:\n",
    "    #     print(f'Error: {response.status_code}')\n",
    "    #     print(f'{response.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28a0c55-1994-4bbd-9943-30c86320dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdic api has a limit of 10000 data points per request\n",
    "# institutions file - FDIC API\n",
    "\n",
    "# base_url_institutions = 'https://banks.data.fdic.gov/api/institutions?'\n",
    "# insti_params = {\n",
    "#     'fields': 'ACTIVE,ADDRESS,ADDRESS2,ASSET,BKCLASS,CBSA,CBSA_DIV,CBSA_DIV_FLG,CBSA_DIV_NO,CBSA_METRO,CBSA_METRO_FLG,CBSA_METRO_NAME,CBSA_MICRO_FLG,CBSA_NO,CITY,CLCODE,COUNTY,ENDEFYMD,ESTYMD,FED,FED_RSSD,INACTIVE,LATITUDE,LONGITUDE,NAME,NETINC,OFFDOM,OFFICES,OFFOA,STCNTY,STNAME,STNUM,UNINUM,WEBADDR,ZIP',\n",
    "#     'format': 'csv'\n",
    "# }\n",
    "# insti_file_path = 'institutions_data.csv'\n",
    "# insti_data_pts = 27825\n",
    "\n",
    "# fdic_api(base_url_institutions, insti_params, insti_file_path, insti_data_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f280f7-9adc-44a0-b2af-0f562bb9cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations file - FDIC API \n",
    "\n",
    "# base_url_locations = 'https://banks.data.fdic.gov/api/locations?'\n",
    "# loc_params = {\n",
    "#     'fields': 'ADDRESS,BKCLASS,CBSA,CBSA_DIV,CBSA_DIV_FLG,CBSA_DIV_NO,CBSA_METRO,CBSA_METRO_FLG,CBSA_METRO_NAME,CBSA_MICRO_FLG,CBSA_NO,CITY,COUNTY,ESTYMD,MAINOFF,NAME,OFFNAME,OFFNUM,SERVTYPE,STALP,STCNTY,STNAME,UNINUM,ZIPCODE',\n",
    "#     'format': 'csv',\n",
    "#     'limit': 10000,\n",
    "#     'offset': 0\n",
    "# }\n",
    "# loc_file_path = 'locations_data.csv'\n",
    "# loc_data_pts = 78908\n",
    "\n",
    "# fdic_api(base_url_locations, loc_params, loc_file_path, loc_data_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7312f19b-2526-41d3-87b9-5ae865ccdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# failures (list of bank failures up to data) - FDIC API \n",
    "\n",
    "# base_url_failures = 'https://banks.data.fdic.gov/api/failures?'\n",
    "# fail_params = {\n",
    "#     'fields': 'NAME,CITYST,FAILDATE,FAILYR,CHCLASS1,RESDATE,RESTYPE,QBFDEP,QBFASSET,COST,PSTALP',\n",
    "#     'format': 'csv', \n",
    "#     'limit': 10000,\n",
    "#     'offset': 0\n",
    "# }\n",
    "# fail_file_path = 'failures_data.csv'\n",
    "# fail_data_pts = 4111\n",
    "\n",
    "# fdic_api(base_url_failures, fail_params, fail_file_path, fail_data_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d3fddc-eae9-4d22-ba71-5128ec3e7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data retrieved successfully. 190714 data points saved to demographics_data.csv\n"
     ]
    }
   ],
   "source": [
    "# demographics (summary of demographic information) - FDIC API \n",
    "# demographics filtered using CALLYM from Jan 2015 - Jan 2025\n",
    "base_url_demographics = 'https://banks.data.fdic.gov/api/demographics?'\n",
    "demo_params = {\n",
    "    'filters': 'CALLYM:[\"201501\" TO \"202501\"]',\n",
    "    'fields': 'ACTEVT,BRANCH,CALLYM,CALLYMD,CBSANAME,CERT,CLCODE,CMSA,CNTRYALP,CNTRYNUM,CNTYNUM,CSA,DIVISION,FDICAREA,METRO,MNRTYCDE,OFFDMULT,OFFTOT,OFFSTATE,WEBADDR',\n",
    "    'format': 'csv',\n",
    "    'limit': 10000,\n",
    "    'offset': 0\n",
    "}\n",
    "demo_file_path = 'demographics_data.csv'\n",
    "demo_data_pts = 190714\n",
    "\n",
    "fdic_api(base_url_demographics, demo_params, demo_file_path, demo_data_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5f595-e699-4280-9a8e-467acd3deb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
